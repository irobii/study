{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch로 시작하는 딥러닝 - 4장. 머신러닝 입문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이 챕터가 다루는 것\n",
    "\n",
    "- classification, regression 이외의 다른 문제 형태\n",
    "\n",
    "- Evaluation 문제, overfitting, underfitting 이해하고 해결하기\n",
    "\n",
    "- deep learning을 위한 data 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝 종류\n",
    "\n",
    "### Supervised learning\n",
    "\n",
    "- Classification: 개와 고양이 분류\n",
    "\n",
    "- Regression: 주식 가격, 크리켓 경기 점수 등을 예측하기\n",
    "\n",
    "- Image segmentation: 픽셀 수준의 분류. 자율주행차에서 중요함.\n",
    "\n",
    "- Speech recognition: OK Google, Alexa, Siri 등\n",
    "\n",
    "- Language translation: 한 언어에서 다른 언어로 스피치 번역\n",
    "\n",
    "### Unsupervised learning\n",
    "\n",
    "- Clustering: 비슷한 데이터 포인트를 같이 그룹핑\n",
    "\n",
    "- Dimensionality Reduction: hidden pattern을 찾기 위한 high-dimensional data를 시각화 하는 것\n",
    "\n",
    "### Reinforcement learning\n",
    "\n",
    "- 최근 각광 받음. 게임에서 human을 이김. AlphaGo 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning glossary\n",
    "\n",
    "- Sample or iput or data point: instances of training a set. image 분류 문제에서 각 image는 sample이나 input이나 data point로 부를 수 있음.\n",
    "\n",
    "- Prediction or output: 알고리즘이 output으로 생성하는 값. 0을 고양이라고 라벨링 하면 0이 predict나 output.\n",
    "\n",
    "- Target or label: 이미지를 태그하는 라벨\n",
    "\n",
    "- Loss value or prediction error: 예측 값과 실제 값 사이의 거리. 값이 작을 수록 정확도가 높아짐.\n",
    "\n",
    "- Classes: 가능한 값이나 라벨의 집합. 전 챕터에서 2개의 클래스인 고양이와 개가 있음.\n",
    "\n",
    "- Binary classification: 2개의 exclusive한 범주 중 하나로 분류되는 것.\n",
    "\n",
    "- Multi-class classification: 2개 이상의 다른 범주로 분류되는 것\n",
    "\n",
    "- Multi-label classification: 입력이 여러 라벨로 태그될 수 있음. 예1) 이탈리안, 멕시칸, 인디안 음식점 예2) 이미지에서 object detection\n",
    "\n",
    "- Scalar regression: 각 입력 데이터 포인트는 하나의 스칼라 quality와 관계 있을 수 있음. 예) 집 값, 주식 값, 크리켓 점수 예측\n",
    "\n",
    "- Vector regression: 하나 이상의 quantity를 예측하는 것. 예) 이미지에서 물고기의 위치를 포함하는 bounding box를 식별하는 것.\n",
    "\n",
    "- Batch: 대부분 batch라고 불리는 입력 샘플의 bunch 위에서 훈련. batch 크기는 GPU의 메모리에 따라 2~256의 값. 각 배치마다 가중치를 업데이트 함으로써 단독 예에서 훈련함으로써 더 빨리 학습함.\n",
    "\n",
    "- Epoch: complete dataset을 통해 알고리즘을 run하는 것을 epoch라고 부름. 몇개의 epoch를 사용하여 weight를 업데이트 해가며 train을 하는 것이 흔함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating machine learning models\n",
    "\n",
    "- training set에 알고리즘을 테스트 하는 것은 알고리즘에 true generalization power를 주지 않음\n",
    "\n",
    "- 대부분의 실세계에서 validation accuracy를 기반으로 다른 방법 (더 많은 layer나 다른 layer)이나 다른 기술을 사용하여 알고리즘을 tweaking함.\n",
    "\n",
    "- 알고리즘은 training이나 validation 데이터에는 잘 작동하지만 보이지 않는 데이터를 일반화하는 것은 실패할 것임. => validation dataset의 information leak 때문임\n",
    "\n",
    "- 이를 피하기 위해 데이터 셋을 training, validation, test 데이터 셋으로 나누는게 중요.\n",
    "\n",
    "- hyperparameter: 네트워크에 사용된 레이어 수, learning rate 등을 콘트롤\n",
    "\n",
    "- overfitting: lack of the algorithm's ability to generalize\n",
    "\n",
    "- underfitting: fail to perform for the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Training, validation, test split\n",
    " \n",
    " **holdout dataset을 사용하는 접근방법**\n",
    " \n",
    " 1. training dataset에 알고리즘을 train\n",
    " \n",
    " 2. validation datasest을 기반으로 hyper parameter tuning 을 수행\n",
    " \n",
    " 3. 알고리즘과 hyper parameter tuning을 freezing한 후에 test dataset에 evaluate\n",
    " \n",
    " \n",
    "## holdout strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Simple holdout validation\n",
    "\n",
    "![](images/DL_With_PyTorch-fig4-1.png)\n",
    "\n",
    "- 작은 데이터셋에서는 단점.\n",
    "\n",
    "- 결과가 consistent하지 않으면 다른 방법을 사용하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. K-fold validation\n",
    "\n",
    "![](images/DL_With_PyTorch-fig4-2.png)\n",
    "\n",
    "\n",
    "- test split을 위해 비율을 유지한채 전체 데이터셋을 k-fold로 나눔 (k=2~10)\n",
    "\n",
    "- 최종 score는 k-fold 동안 얻어진 score를 평균냄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. K-fold validation with shuffle\n",
    "\n",
    "- Data representatativeness: 샘플을 split하거나 stratify하기 전에 good mix가 중요. stratified 샘플링은 validation과 test 데이터 셋트를 생성하기 위한 각 category 로부터  data point를 선택하는 것임.\n",
    "\n",
    "- Time sensitivity: information leak이 일어나지 않게 domain-specifid knowledge로 시간의 영향을 알도록 한다.\n",
    "\n",
    "- Data redundancy: training, validation, test 셋트가 unique해야 함, => 중복되면 unseen data에 대한 generalization이 잘 되지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing and feature engineering\n",
    "\n",
    "- Vectorization: 다양한 형태의 데이터 (텍스트, 사운드, 이미지, 비디오)를 PyTorch tensor로 변환. 예) `torchvision`은 Pytho Image Library (PIL)  image를 tensor object로 변환함.\n",
    "\n",
    "- Normilization: 사전 normalized feature는 algorithm training 을 더 빠르고 성능이 좋게 함. (예: 평균을 0, 표준편차를 1)\n",
    "\n",
    "- Missing values\n",
    "\n",
    "- Feature extraction: domain knowledge로 추출 => 적은 컴퓨터 자원으로 더 빨리 문제 해결. 딥러닝은 대규모의 데이터로 수동으로 엔지니어링 할 필요 없이  feature 학습하지만 데이터가 tight하면 good feature engineering에 집중하라."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting and underfitting\n",
    "\n",
    "### Overfitting을 피하기 위한 방법\n",
    "\n",
    "- Getting more data\n",
    "\n",
    "- Reducing the size of the network\n",
    "\n",
    "- Applying weight regularizer\n",
    "\n",
    "- Applying dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 아키텍처 복잡도 줄이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Architecture1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Architecture1, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)      \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Architecture2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Architecture2, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch 레이어에 정규화 추가(Regularizer)\n",
    "\n",
    "- L1 regularization: The sum of absolute values of weight coefficients are added to the cost.\n",
    "\n",
    "- L2 regularization: The sum of squres of weight coefficients are added to the cost. (`weight_decay` parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Architecture1(10,20,2)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5) #weight_decay default 값은 0, 보통 1e-5 같은 작은 값을 설정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout\n",
    "![](images/DL_With_PyTorch-fig4-3.png)\n",
    "\n",
    "![](images/DL_With_PyTorch-fig4-4.png)\n",
    "\n",
    "- training 동안 모델의 intermediate layer에 응용. drop out은 보통 0.2~0.5\n",
    "\n",
    "- Pytorch는 다른 layer로 drop out을 제공해서 사용하기 용이하게 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.dropout(x, training=True)`\n",
    "\n",
    "training=True면 training을, false이면 validation 이나 test phase에 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting\n",
    "\n",
    "- Acquire more data\n",
    "\n",
    "- Increase the complexity of the model: layer #, weight #, parameter 를 증가\n",
    "\n",
    "- Regularization을 사용하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow of a machine learning project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem definition and dataset creation\n",
    "\n",
    "- Input data와 target label은 무엇인가?\n",
    "\n",
    "- problem type을 identify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure of success\n",
    "\n",
    "- Balanced classification problem: ROC, Area under the curve (AUC)\n",
    "\n",
    "- Imbalanced dataset: precision, recall\n",
    "\n",
    "- Ranking problem: mean average precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation protocol\n",
    "\n",
    "- Holdout validation set: 데이터가 충분할때 가장 흔히 사용\n",
    "\n",
    "- K-fold cross validation: limited data에서 자료의 비율이 다를때 평가하는데 좋은 성능\n",
    "\n",
    "- Iterated  k-fold cross validation: model preformance에 더 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare you data\n",
    "\n",
    "## Baseline model\n",
    "\n",
    "- Choice of last layer\n",
    "\n",
    "- Choice of loss function\n",
    "\n",
    "- Optimization\n",
    "\n",
    "![](images/DL_With_PyTorch-fig4-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large model enough to overfit\n",
    "\n",
    "- Add more layers to your existing architecture\n",
    "\n",
    "- Add more weight to th existing layers\n",
    "\n",
    "- Train it for more epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying regularization\n",
    "\n",
    "- Adding dropout: 실험을 통해 가장 잘 위치한 공간을 찾아 different layer 사이에 add. 0.2부터 시작하는게 좋은 전략\n",
    "\n",
    "- Trying different architectures: activation function, # of layer, weights, parameter 등 different architectures 사용\n",
    "\n",
    "- Adding L1, L2 regularization\n",
    "\n",
    "- Trying different learning rates\n",
    "\n",
    "- Adding more features or more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate picking strategies\n",
    "\n",
    "`torch.optim.lr_scheduler`: learning rate를 dynamic하게 tune\n",
    "\n",
    "- StepLR : 1) step size: # of epochs the learning rate has to change 2) gamma: how much the learning rate has to be change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "for epoch in range(100):\n",
    "    scheduler.step()\n",
    "    train(...)\n",
    "    validate(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MultiStepLR: StepLR과 비슷하지만, step이 list로 주어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "scheduler = MultiStepLR(optimizer, milestones=[30, 80], gamma=0.1)\n",
    "\n",
    "for epoch in range(100):\n",
    "    scheduler.step()\n",
    "    train(...)\n",
    "    validate(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ReduceLROnPlateau: 특정 metric(training loss, validation loss, accuracy stagnate)에 learning rate가 바뀌는 것. 2~10 times로 learning rate 감소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "for epoch in range(100):\n",
    "    train(...)\n",
    "    val_loss = validate(...)\n",
    "    # Note that step should be called after validate()\n",
    "    scheduler.step(val_loss)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "머신러닝이나 딥러닝 문제를 푸는데 사용되는 common and best practice를 다룸\n",
    "\n",
    "- creating problem statements\n",
    "\n",
    "- choosing the algorithm\n",
    "\n",
    "- beating the baseline score\n",
    "\n",
    "- increasing the capacity of the model until it overfits the dataset\n",
    "\n",
    "- applying regularization techniques that can prevent overfitting\n",
    "\n",
    "- increasing the generalization capacity\n",
    "\n",
    "- tuning different parameters of the model or algorithms\n",
    "\n",
    "- exploring different learning strategies that can be used to train deep learning models optimally and faster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
